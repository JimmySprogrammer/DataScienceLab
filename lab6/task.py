# -*- coding: utf-8 -*-
"""
Lab6 æ·±åº¦å­¦ä¹ æ’åé¢„æµ‹ä¸èšç±»åˆ†æ
æ•°æ®æ¥æº: D:\DataScienceLab\lab5\data\merged_all.csv
è¾“å‡ºæ–‡ä»¶:
  - D:\DataScienceLab\lab6\ranking_predictions.csv
  - D:\DataScienceLab\lab6\clustering_results.csv
  - D:\DataScienceLab\lab6\cluster_visualization.png
"""

import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error

# ========== 1. è·¯å¾„ä¸æ–‡ä»¶æ£€æŸ¥ ==========
data_path = r"D:\DataScienceLab\lab5\data\merged_all.csv"
save_dir = r"D:\DataScienceLab\lab6"
os.makedirs(save_dir, exist_ok=True)

print(f"ğŸ“Š è¯»å–æ•°æ®: {data_path}")
data = pd.read_csv(data_path)
print(f"åŸå§‹è¡Œæ•°: {len(data)}")
print("åˆ—:", list(data.columns))

# ========== 2. æ•°æ®æ¸…æ´— ==========
data = data.dropna(subset=['Institutions', 'Discipline', 'Cites', 'Web of Science Documents'])
data = data[data['Cites'] > 0]
data = data[data['Web of Science Documents'] > 0]

# è®¡ç®—æ¯ä¸ªæœºæ„æ¯ä¸ªå­¦ç§‘çš„â€œå½±å“å¾—åˆ†â€
data['Impact_Score'] = data['Cites'] / data['Web of Science Documents']

# ========== 3. æ·±åº¦å­¦ä¹ æ¨¡å‹é¢„æµ‹æ’å ==========
print("\nğŸ« å¼€å§‹è®­ç»ƒå­¦ç§‘æ’åé¢„æµ‹æ¨¡å‹ï¼ˆDeep Learningï¼‰...")
results = []

for discipline, group in data.groupby('Discipline'):
    if len(group) < 300:
        continue
    X = group[['Web of Science Documents', 'Cites', 'Cites/Paper', 'Top Papers']].values
    y = group['Impact_Score'].values

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)

    model = Sequential([
        Dense(32, activation='relu', input_shape=(X_train.shape[1],)),
        Dense(16, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer=Adam(0.01), loss='mse')
    model.fit(X_train, y_train, epochs=30, batch_size=16, verbose=0)

    y_pred = model.predict(X_test).flatten()
    mse = mean_squared_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    results.append((discipline, len(group), mse, mape))

    print(f"[{discipline}] n={len(group)} MSE={mse:.2f} MAPE={mape:.3f}")

# ä¿å­˜é¢„æµ‹ç»“æœ
ranking_df = pd.DataFrame(results, columns=['Discipline', 'Samples', 'MSE', 'MAPE'])
ranking_csv = os.path.join(save_dir, "ranking_predictions.csv")
ranking_df.to_csv(ranking_csv, index=False, encoding='utf-8-sig')
print(f"\nâœ… æ·±åº¦å­¦ä¹ æ’åé¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {ranking_csv}")

# ========== 4. èšç±»åˆ†æ ==========
print("\nğŸ” å¼€å§‹èšç±»åˆ†æ (KMeans)...")

# èšç±»ç‰¹å¾
features = ['Web of Science Documents', 'Cites', 'Cites/Paper', 'Top Papers']
X = data[features].values
X_scaled = StandardScaler().fit_transform(X)

# èšç±»
kmeans = KMeans(n_clusters=8, random_state=42)
data['Cluster'] = kmeans.fit_predict(X_scaled)

# ä¿å­˜èšç±»ç»“æœ
cluster_csv = os.path.join(save_dir, "clustering_results.csv")
data[['Institutions', 'Discipline', 'Cluster']].to_csv(cluster_csv, index=False, encoding='utf-8-sig')
print(f"âœ… èšç±»ç»“æœå·²ä¿å­˜åˆ°: {cluster_csv}")

# å¯»æ‰¾ä¸â€œEast China Normal Universityâ€ç±»ä¼¼çš„å­¦æ ¡
target_name = "East China Normal University"
if target_name in data['Institutions'].values:
    target_cluster = data[data['Institutions'] == target_name]['Cluster'].iloc[0]
    similar = data[data['Cluster'] == target_cluster]['Institutions'].unique()
    print(f"\nğŸ« ä¸ {target_name} ç±»ä¼¼çš„å­¦æ ¡:")
    print(similar[:10])
else:
    print(f"\nâš ï¸ æœªæ‰¾åˆ° {target_name}ï¼Œè¯·æ£€æŸ¥æ•°æ®ä¸­æœºæ„åç§°æ˜¯å¦ä¸€è‡´")

# å¯è§†åŒ–
pca = PCA(n_components=2)
reduced = pca.fit_transform(X_scaled)
plt.figure(figsize=(8,6))
plt.scatter(reduced[:,0], reduced[:,1], c=data['Cluster'], cmap='tab10', alpha=0.7)
plt.title("ESI Institutions Clustering Visualization")
plt.xlabel("PCA-1")
plt.ylabel("PCA-2")

img_path = os.path.join(save_dir, "cluster_visualization.png")
plt.savefig(img_path, dpi=300)
plt.close()
print(f"âœ… èšç±»å¯è§†åŒ–å›¾å·²ä¿å­˜åˆ°: {img_path}")

print("\nğŸ¯ å…¨éƒ¨å®Œæˆï¼ç»“æœæ–‡ä»¶å·²ç”Ÿæˆåœ¨ D:\\DataScienceLab\\lab6\\")
