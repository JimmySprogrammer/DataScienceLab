# -*- coding: utf-8 -*-
"""
æˆ¿å±‹ä»·æ ¼æ•°æ®é¢„å¤„ç†å®Œæ•´ä»£ç 
å®éªŒäºŒï¼šæ•°æ®é¢„å¤„ç†çš„åŸºæœ¬æ–¹æ³•
"""

# =============================================================================
# 1. å¯¼å…¥å¿…è¦çš„åº“
# =============================================================================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.preprocessing import StandardScaler
from sklearn.impute import KNNImputer
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

print("åº“å¯¼å…¥å®Œæˆ")

# =============================================================================
# 2. åŠ è½½æ•°æ®å¹¶è¿›è¡Œåˆæ­¥æ¢ç´¢
# =============================================================================
try:
    # åŠ è½½æ•°æ®
    df = pd.read_csv('train.csv')
    print(f"æ•°æ®åŠ è½½æˆåŠŸï¼æ•°æ®é›†å½¢çŠ¶: {df.shape}")
    
    # æ£€æŸ¥ç›®æ ‡å˜é‡æ˜¯å¦å­˜åœ¨ï¼ˆå¯èƒ½æ˜¯SalePriceæˆ–priceï¼‰
    if 'SalePrice' in df.columns:
        target_col = 'SalePrice'
    elif 'price' in df.columns:
        target_col = 'price'
    else:
        # å¦‚æœéƒ½æ²¡æœ‰ï¼Œå‡è®¾ç¬¬ä¸€åˆ—æ˜¯ç›®æ ‡å˜é‡æˆ–è€…ä½¿ç”¨å…¶ä»–é€»è¾‘
        target_col = df.columns[-1]  # å‡è®¾æœ€åä¸€åˆ—æ˜¯ç›®æ ‡å˜é‡
        print(f"æœªæ‰¾åˆ°æ ‡å‡†çš„ç›®æ ‡å˜é‡åï¼Œä½¿ç”¨ '{target_col}' ä½œä¸ºç›®æ ‡å˜é‡")
    
    # åˆæ­¥æ•°æ®æ¢ç´¢
    print("\næ•°æ®åŸºæœ¬ä¿¡æ¯:")
    print(f"æ•°æ®é›†å½¢çŠ¶: {df.shape}")
    print(f"è¡Œæ•°: {df.shape[0]}, åˆ—æ•°: {df.shape[1]}")
    
    print("\nå‰3è¡Œæ•°æ®:")
    display(df.head(3))
    
    print("\næ•°æ®åˆ—ä¿¡æ¯:")
    df.info()
    
    print("\næ•°å€¼å‹ç‰¹å¾çš„æè¿°æ€§ç»Ÿè®¡:")
    display(df.describe())
    
except FileNotFoundError:
    print("é”™è¯¯: æœªæ‰¾åˆ° 'train.csv' æ–‡ä»¶")
    print("è¯·ç¡®ä¿æ–‡ä»¶åœ¨å½“å‰å·¥ä½œç›®å½•ä¸­")
    # åˆ›å»ºç¤ºä¾‹æ•°æ®æ¡†æ¶ä¾›æ¼”ç¤ºï¼ˆå®é™…ä½¿ç”¨æ—¶è¯·æ³¨é‡Šæ‰ï¼‰
    print("åˆ›å»ºç¤ºä¾‹æ•°æ®ä¾›æ¼”ç¤º...")
    np.random.seed(42)
    n_samples = 1000
    df = pd.DataFrame({
        'SalePrice': np.random.normal(180000, 50000, n_samples),
        'OverallQual': np.random.randint(1, 11, n_samples),
        'GrLivArea': np.random.normal(1500, 500, n_samples),
        'GarageCars': np.random.randint(0, 4, n_samples),
        'TotalBsmtSF': np.random.normal(1000, 300, n_samples),
        'LotArea': np.random.normal(10000, 3000, n_samples),
        'YearBuilt': np.random.randint(1950, 2010, n_samples),
        'MSSubClass': np.random.choice([20, 30, 40, 50, 60, 70, 80, 90, 120, 150, 160, 180, 190], n_samples),
        'MSZoning': np.random.choice(['RL', 'RM', 'FV', 'RH'], n_samples),
        'LotFrontage': np.random.normal(70, 20, n_samples)
    })
    # äººä¸ºæ·»åŠ ä¸€äº›ç¼ºå¤±å€¼
    for col in ['LotFrontage', 'GarageCars']:
        df.loc[df.sample(frac=0.1).index, col] = np.nan
    target_col = 'SalePrice'
    print("âœ… ç¤ºä¾‹æ•°æ®åˆ›å»ºå®Œæˆ")

# =============================================================================
# 3. ç¼ºå¤±å€¼æ£€æµ‹ä¸å¤„ç†
# =============================================================================
print("\n" + "="*60)
print("3. ç¼ºå¤±å€¼æ£€æµ‹ä¸å¤„ç†")
print("="*60)

# 3.1 ç¼ºå¤±å€¼æ£€æµ‹
missing_ratio = (df.isnull().sum() / len(df)) * 100
missing_data = pd.DataFrame({
    'ç¼ºå¤±æ•°é‡': df.isnull().sum(),
    'ç¼ºå¤±æ¯”ä¾‹%': missing_ratio
})
missing_data = missing_data[missing_data['ç¼ºå¤±æ•°é‡'] > 0].sort_values('ç¼ºå¤±æ¯”ä¾‹%', ascending=False)

print("ç¼ºå¤±å€¼ç»Ÿè®¡:")
if len(missing_data) > 0:
    display(missing_data)
else:
    print("æ•°æ®é›†ä¸­æ²¡æœ‰ç¼ºå¤±å€¼")

# å¯è§†åŒ–ç¼ºå¤±å€¼
if len(missing_data) > 0:
    plt.figure(figsize=(12, 6))
    missing_ratio_plot = missing_ratio[missing_ratio > 0].sort_values(ascending=False)
    sns.barplot(x=missing_ratio_plot.index, y=missing_ratio_plot.values)
    plt.xticks(rotation=90)
    plt.title('ç‰¹å¾ç¼ºå¤±å€¼æ¯”ä¾‹')
    plt.ylabel('ç¼ºå¤±ç™¾åˆ†æ¯” (%)')
    plt.tight_layout()
    plt.show()

# 3.2 ç¼ºå¤±å€¼å¤„ç†
df_cleaned = df.copy()

print("\nå¼€å§‹å¤„ç†ç¼ºå¤±å€¼...")

if len(missing_data) > 0:
    # ç­–ç•¥1ï¼šåˆ é™¤ç¼ºå¤±ç‡è¿‡é«˜çš„ç‰¹å¾ï¼ˆé˜ˆå€¼è®¾ä¸º20%ï¼‰
    high_missing_threshold = 20
    high_missing_columns = missing_ratio[missing_ratio > high_missing_threshold].index
    if len(high_missing_columns) > 0:
        df_cleaned = df_cleaned.drop(columns=high_missing_columns)
        print(f"å·²åˆ é™¤ç¼ºå¤±ç‡ > {high_missing_threshold}% çš„ç‰¹å¾: {list(high_missing_columns)}")
    else:
        print(f"æ²¡æœ‰ç¼ºå¤±ç‡ > {high_missing_threshold}% çš„ç‰¹å¾")

    # æ›´æ–°ç±»åˆ«å’Œæ•°å€¼ç‰¹å¾åˆ—è¡¨
    cat_columns = df_cleaned.select_dtypes(include=['object']).columns
    num_columns = df_cleaned.select_dtypes(include=[np.number]).columns

    # ç­–ç•¥2ï¼šå¡«å……ç±»åˆ«ç‰¹å¾
    categorical_fill_columns = [col for col in cat_columns if col in df_cleaned.columns and df_cleaned[col].isnull().sum() > 0]
    
    if len(categorical_fill_columns) > 0:
        print("ğŸ”§ å¤„ç†ç±»åˆ«ç‰¹å¾ç¼ºå¤±å€¼...")
        for col in categorical_fill_columns:
            # å¯¹äºè¡¨ç¤º"æ²¡æœ‰"çš„ç‰¹å¾ï¼Œç”¨'None'å¡«å……
            none_fill_columns = ['Alley', 'Fence', 'MiscFeature', 'FireplaceQu', 'GarageType', 
                               'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 
                               'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'PoolQC']
            
            if col in none_fill_columns:
                df_cleaned[col].fillna('None', inplace=True)
                print(f"   {col}: ç”¨ 'None' å¡«å……")
            else:
                # å…¶ä»–ç±»åˆ«ç‰¹å¾ç”¨ä¼—æ•°å¡«å……
                mode_val = df_cleaned[col].mode()[0] if not df_cleaned[col].mode().empty else 'Unknown'
                df_cleaned[col].fillna(mode_val, inplace=True)
                print(f"   {col}: ç”¨ä¼—æ•° '{mode_val}' å¡«å……")

    # ç­–ç•¥3ï¼šå¡«å……æ•°å€¼ç‰¹å¾
    numerical_fill_columns = [col for col in num_columns if col in df_cleaned.columns and df_cleaned[col].isnull().sum() > 0]
    
    if len(numerical_fill_columns) > 0:
        print("ğŸ”§ å¤„ç†æ•°å€¼ç‰¹å¾ç¼ºå¤±å€¼...")
        # ä½¿ç”¨ä¸­ä½æ•°å¡«å……ï¼ˆæ›´ç¨³å¥ï¼‰
        for col in numerical_fill_columns:
            if col != target_col:  # ä¸å¡«å……ç›®æ ‡å˜é‡
                median_val = df_cleaned[col].median()
                df_cleaned[col].fillna(median_val, inplace=True)
                print(f"   {col}: ç”¨ä¸­ä½æ•° {median_val:.2f} å¡«å……")

    # éªŒè¯æ˜¯å¦è¿˜æœ‰ç¼ºå¤±å€¼
    remaining_missing = df_cleaned.isnull().sum().sum()
    print(f"ç¼ºå¤±å€¼å¤„ç†å®Œæˆï¼å‰©ä½™ç¼ºå¤±å€¼æ•°é‡: {remaining_missing}")

else:
    print("æ•°æ®é›†ä¸­æ²¡æœ‰ç¼ºå¤±å€¼ï¼Œè·³è¿‡ç¼ºå¤±å€¼å¤„ç†æ­¥éª¤")

print(f"æ¸…ç†åæ•°æ®é›†å½¢çŠ¶: {df_cleaned.shape}")

# =============================================================================
# 4. å¼‚å¸¸å€¼æ£€æµ‹
# =============================================================================
print("\n" + "="*60)
print("4. å¼‚å¸¸å€¼æ£€æµ‹")
print("="*60)

# æ›´æ–°æ•°å€¼åˆ—ï¼ˆå¤„ç†ç¼ºå¤±å€¼åï¼‰
num_columns_cleaned = df_cleaned.select_dtypes(include=[np.number]).columns

# 4.1 Z-score å¼‚å¸¸å€¼æ£€æµ‹ (|Z| > 3)
print("ä½¿ç”¨Z-scoreæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼...")
z_scores = stats.zscore(df_cleaned[num_columns_cleaned], nan_policy='omit')
# å¤„ç†å¯èƒ½çš„NaNå€¼ï¼ˆç”±äºæ ‡å‡†å·®ä¸º0å¯¼è‡´çš„ï¼‰
z_scores = np.where(np.isnan(z_scores), 0, z_scores)

outliers_z = (np.abs(z_scores) > 3).sum(axis=0)
outliers_z_data = pd.DataFrame({
    'ç‰¹å¾': num_columns_cleaned,
    'å¼‚å¸¸å€¼æ•°é‡': outliers_z
}).sort_values('å¼‚å¸¸å€¼æ•°é‡', ascending=False)

print("Z-scoreæ£€æµ‹ç»“æœï¼ˆå¼‚å¸¸å€¼æ•°é‡>0çš„ç‰¹å¾ï¼‰:")
display(outliers_z_data[outliers_z_data['å¼‚å¸¸å€¼æ•°é‡'] > 0].head(10))

# 4.2 IQR å¼‚å¸¸å€¼æ£€æµ‹
print("\nä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼...")
def detect_outliers_iqr(series):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return series[(series < lower_bound) | (series > upper_bound)]

# å¯¹å…³é”®æ•°å€¼ç‰¹å¾è¿›è¡ŒIQRæ£€æµ‹
key_features = ['LotArea', 'GrLivArea', 'TotalBsmtSF', target_col]
key_features = [f for f in key_features if f in df_cleaned.columns]

outliers_iqr_summary = {}
for feature in key_features:
    outliers = detect_outliers_iqr(df_cleaned[feature])
    outliers_iqr_summary[feature] = len(outliers)

outliers_iqr_data = pd.DataFrame.from_dict(outliers_iqr_summary, 
                                         orient='index', 
                                         columns=['å¼‚å¸¸å€¼æ•°é‡']).sort_values('å¼‚å¸¸å€¼æ•°é‡', ascending=False)

print("IQRæ£€æµ‹ç»“æœï¼ˆå…³é”®ç‰¹å¾ï¼‰:")
display(outliers_iqr_data)

# 4.3 å¯è§†åŒ–å…³é”®ç‰¹å¾çš„å¼‚å¸¸å€¼
print("\nå¼‚å¸¸å€¼å¯è§†åŒ–...")
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
axes = axes.ravel()

for i, feature in enumerate(key_features[:4]):  # åªæ˜¾ç¤ºå‰4ä¸ªç‰¹å¾
    if i < len(axes):
        # ç®±çº¿å›¾
        df_cleaned.boxplot(column=feature, ax=axes[i])
        axes[i].set_title(f'{feature} - ç®±çº¿å›¾')
        
plt.tight_layout()
plt.show()

# 4.4 æ•£ç‚¹å›¾å¯è§†åŒ–ï¼ˆGrLivArea vs SalePriceï¼‰
if 'GrLivArea' in df_cleaned.columns and target_col in df_cleaned.columns:
    plt.figure(figsize=(10, 6))
    plt.scatter(df_cleaned['GrLivArea'], df_cleaned[target_col], alpha=0.6)
    plt.title(f'GrLivArea vs {target_col} (å¼‚å¸¸å€¼æ£€æµ‹)')
    plt.xlabel('Above grade living area (å¹³æ–¹è‹±å°º)')
    plt.ylabel(f'{target_col} (ç¾å…ƒ)')
    
    # æ ‡è®°å¯èƒ½çš„å¼‚å¸¸å€¼åŒºåŸŸ
    Q1_gr = df_cleaned['GrLivArea'].quantile(0.25)
    Q3_gr = df_cleaned['GrLivArea'].quantile(0.75)
    IQR_gr = Q3_gr - Q1_gr
    upper_bound_gr = Q3_gr + 1.5 * IQR_gr
    
    Q1_price = df_cleaned[target_col].quantile(0.25)
    Q3_price = df_cleaned[target_col].quantile(0.75)
    IQR_price = Q3_price - Q1_price
    lower_bound_price = Q1_price - 1.5 * IQR_price
    
    # æ ‡è®°å¼‚å¸¸åŒºåŸŸ
    plt.axvline(x=upper_bound_gr, color='red', linestyle='--', alpha=0.7, label='GrLivAreaå¼‚å¸¸é˜ˆå€¼')
    plt.axhline(y=lower_bound_price, color='orange', linestyle='--', alpha=0.7, label=f'{target_col}å¼‚å¸¸é˜ˆå€¼')
    plt.legend()
    plt.show()

# 4.5 å¤„ç†å¼‚å¸¸å€¼ï¼ˆé€‰æ‹©æ€§åˆ é™¤ï¼‰
print("\nå¤„ç†å¼‚å¸¸å€¼...")
original_shape = df_cleaned.shape

# ç¤ºä¾‹ï¼šåˆ é™¤GrLivAreaè¿‡å¤§ä½†ä»·æ ¼å¼‚å¸¸ä½çš„ç‚¹
if 'GrLivArea' in df_cleaned.columns and target_col in df_cleaned.columns:
    # è®¡ç®—IQRè¾¹ç•Œ
    Q1_gr = df_cleaned['GrLivArea'].quantile(0.25)
    Q3_gr = df_cleaned['GrLivArea'].quantile(0.75)
    IQR_gr = Q3_gr - Q1_gr
    upper_bound_gr = Q3_gr + 1.5 * IQR_gr
    
    Q1_price = df_cleaned[target_col].quantile(0.25)
    Q3_price = df_cleaned[target_col].quantile(0.75)
    IQR_price = Q3_price - Q1_price
    lower_bound_price = Q1_price - 1.5 * IQR_price
    
    # åˆ é™¤æ˜æ˜¾çš„å¼‚å¸¸ç‚¹ï¼ˆå³ä¸‹è§’çš„ç‚¹ï¼šé¢ç§¯å¤§ä½†ä»·æ ¼ä½ï¼‰
    outlier_mask = (df_cleaned['GrLivArea'] > upper_bound_gr) & (df_cleaned[target_col] < lower_bound_price)
    df_cleaned = df_cleaned[~outlier_mask]
    
    removed_count = outlier_mask.sum()
    print(f"åˆ é™¤äº† {removed_count} ä¸ªæ˜æ˜¾å¼‚å¸¸ç‚¹")

print(f"å¼‚å¸¸å€¼å¤„ç†å®Œæˆï¼æ•°æ®é›†ä» {original_shape} å˜ä¸º {df_cleaned.shape}")

# =============================================================================
# 5. ç‰¹å¾é—´çš„ç›¸å…³æ€§åˆ†æ
# =============================================================================
print("\n" + "="*60)
print("5. ç‰¹å¾é—´çš„ç›¸å…³æ€§åˆ†æ")
print("="*60)

# æ›´æ–°æ•°å€¼åˆ—
num_columns_final = df_cleaned.select_dtypes(include=[np.number]).columns

if target_col in num_columns_final:
    # 5.1 è®¡ç®—ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§
    correlation_with_target = df_cleaned[num_columns_final].corr()[target_col].sort_values(ascending=False)
    
    print(f"ç‰¹å¾ä¸ {target_col} çš„ç›¸å…³æ€§æ’å:")
    print("æ­£ç›¸å…³æœ€é«˜çš„10ä¸ªç‰¹å¾:")
    display(correlation_with_target.head(11))  # æ˜¾ç¤º11ä¸ªï¼ˆåŒ…å«ç›®æ ‡å˜é‡è‡ªèº«ï¼‰
    
    print("\nè´Ÿç›¸å…³æœ€é«˜çš„5ä¸ªç‰¹å¾:")
    display(correlation_with_target.tail(5))
    
    # 5.2 ç»˜åˆ¶ç›¸å…³æ€§çƒ­å›¾ï¼ˆå‰15ä¸ªç›¸å…³ç‰¹å¾ï¼‰
    top_corr_features = correlation_with_target.head(16).index  # å–å‰16ä¸ªï¼ˆåŒ…å«ç›®æ ‡å˜é‡ï¼‰
    top_corr_features = [f for f in top_corr_features if f != target_col][:15]  # æ’é™¤ç›®æ ‡å˜é‡ï¼Œå–15ä¸ª
    top_corr_features.append(target_col)  # æœ€ååŠ å…¥ç›®æ ‡å˜é‡
    
    plt.figure(figsize=(12, 10))
    correlation_matrix = df_cleaned[top_corr_features].corr()
    
    # åˆ›å»ºmaskæ¥éšè—ä¸Šä¸‰è§’
    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
    
    sns.heatmap(correlation_matrix, 
                mask=mask,
                annot=True, 
                cmap='RdBu_r', 
                center=0,
                fmt='.2f',
                square=True,
                cbar_kws={"shrink": .8})
    plt.title('Top 15 æ•°å€¼ç‰¹å¾ç›¸å…³æ€§çƒ­å›¾')
    plt.tight_layout()
    plt.show()
    
    # 5.3 ç»˜åˆ¶ç›¸å…³æ€§æ¡å½¢å›¾
    plt.figure(figsize=(12, 6))
    top_15_corr = correlation_with_target.head(16)[1:16]  # æ’é™¤ç›®æ ‡å˜é‡è‡ªèº«ï¼Œå–2-16
    colors = ['red' if x > 0 else 'blue' for x in top_15_corr.values]
    
    sns.barplot(x=top_15_corr.values, y=top_15_corr.index, palette=colors)
    plt.title(f'ä¸ {target_col} ç›¸å…³æ€§æœ€é«˜çš„15ä¸ªç‰¹å¾')
    plt.xlabel('ç›¸å…³ç³»æ•°')
    plt.tight_layout()
    plt.show()
    
else:
    print(f"ç›®æ ‡å˜é‡ {target_col} ä¸æ˜¯æ•°å€¼ç±»å‹ï¼Œæ— æ³•è¿›è¡Œç›¸å…³æ€§åˆ†æ")

# =============================================================================
# 6. å¯¹ Price å±æ€§è¿›è¡Œæ ‡å‡†åŒ–
# =============================================================================
print("\n" + "="*60)
print("6. å¯¹ Price å±æ€§è¿›è¡Œæ ‡å‡†åŒ–")
print("="*60)

if target_col in df_cleaned.columns:
    # åˆ›å»ºæ ‡å‡†åŒ–åçš„æ–°åˆ—
    scaler = StandardScaler()
    standardized_col_name = f'{target_col}_Standardized'
    
    df_cleaned[standardized_col_name] = scaler.fit_transform(df_cleaned[[target_col]])
    
    # æŸ¥çœ‹æ ‡å‡†åŒ–å‰åçš„å¯¹æ¯”
    print("æ ‡å‡†åŒ–å‰åå¯¹æ¯”:")
    print(f"åŸå§‹ {target_col} - å‡å€¼: {df_cleaned[target_col].mean():.2f}, æ ‡å‡†å·®: {df_cleaned[target_col].std():.2f}")
    print(f"æ ‡å‡†åŒ–å - å‡å€¼: {df_cleaned[standardized_col_name].mean():.2f}, æ ‡å‡†å·®: {df_cleaned[standardized_col_name].std():.2f}")
    
    # å¯è§†åŒ–æ ‡å‡†åŒ–å‰åçš„åˆ†å¸ƒ
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # åŸå§‹åˆ†å¸ƒ
    ax1.hist(df_cleaned[target_col], bins=30, color='skyblue', edgecolor='black', alpha=0.7)
    ax1.axvline(df_cleaned[target_col].mean(), color='red', linestyle='--', label=f'å‡å€¼: {df_cleaned[target_col].mean():.2f}')
    ax1.set_title(f'åŸå§‹ {target_col} åˆ†å¸ƒ')
    ax1.set_xlabel(target_col)
    ax1.set_ylabel('é¢‘ç‡')
    ax1.legend()
    
    # æ ‡å‡†åŒ–ååˆ†å¸ƒ
    ax2.hist(df_cleaned[standardized_col_name], bins=30, color='lightcoral', edgecolor='black', alpha=0.7)
    ax2.axvline(df_cleaned[standardized_col_name].mean(), color='red', linestyle='--', label=f'å‡å€¼: {df_cleaned[standardized_col_name].mean():.2f}')
    ax2.set_title(f'æ ‡å‡†åŒ–åçš„ {target_col} åˆ†å¸ƒ')
    ax2.set_xlabel('Standardized ' + target_col)
    ax2.set_ylabel('é¢‘ç‡')
    ax2.legend()
    
    plt.tight_layout()
    plt.show()
    
else:
    print(f"ç›®æ ‡å˜é‡ {target_col} ä¸å­˜åœ¨äºæ•°æ®é›†ä¸­")

# =============================================================================
# 7. æ ¹æ® Price å±æ€§è¿›è¡Œç¦»æ•£åŒ–
# =============================================================================
print("\n" + "="*60)
print("7. æ ¹æ® Price å±æ€§è¿›è¡Œç¦»æ•£åŒ–")
print("="*60)

if target_col in df_cleaned.columns:
    # æ–¹æ³•1ï¼šç­‰å®½åˆ†ç®±ï¼ˆåŸºäºå€¼èŒƒå›´ï¼‰
    df_cleaned['Price_Category_EqualWidth'] = pd.cut(df_cleaned[target_col], 
                                                   bins=3, 
                                                   labels=['ä½ä»·', 'ä¸­ä»·', 'é«˜ä»·'])
    
    # æ–¹æ³•2ï¼šç­‰é¢‘åˆ†ç®±ï¼ˆåŸºäºæ•°æ®é‡ï¼‰
    df_cleaned['Price_Category_EqualFreq'] = pd.qcut(df_cleaned[target_col], 
                                                    q=3, 
                                                    labels=['ä½ä»·', 'ä¸­ä»·', 'é«˜ä»·'])
    
    print("ç¦»æ•£åŒ–ç»“æœç»Ÿè®¡:")
    
    print("\nç­‰å®½åˆ†ç®±ç»“æœ:")
    equal_width_counts = df_cleaned['Price_Category_EqualWidth'].value_counts().sort_index()
    display(equal_width_counts)
    
    print("\nç­‰é¢‘åˆ†ç®±ç»“æœ:")
    equal_freq_counts = df_cleaned['Price_Category_EqualFreq'].value_counts().sort_index()
    display(equal_freq_counts)
    
    # å¯è§†åŒ–ç¦»æ•£åŒ–ç»“æœ
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # ç­‰å®½åˆ†ç®±
    equal_width_counts.plot(kind='bar', ax=ax1, color=['lightblue', 'lightgreen', 'salmon'])
    ax1.set_title('ç­‰å®½åˆ†ç®± - ä»·æ ¼ç­‰çº§åˆ†å¸ƒ')
    ax1.set_xlabel('ä»·æ ¼ç­‰çº§')
    ax1.set_ylabel('æ•°é‡')
    
    # ç­‰é¢‘åˆ†ç®±
    equal_freq_counts.plot(kind='bar', ax=ax2, color=['lightblue', 'lightgreen', 'salmon'])
    ax2.set_title('ç­‰é¢‘åˆ†ç®± - ä»·æ ¼ç­‰çº§åˆ†å¸ƒ')
    ax2.set_xlabel('ä»·æ ¼ç­‰çº§')
    ax2.set_ylabel('æ•°é‡')
    
    plt.tight_layout()
    plt.show()
    
    # æ˜¾ç¤ºæ¯ä¸ªä»·æ ¼åŒºé—´çš„å®é™…èŒƒå›´
    print("\nç­‰å®½åˆ†ç®±çš„ä»·æ ¼èŒƒå›´:")
    price_ranges = pd.cut(df_cleaned[target_col], bins=3)
    print(price_ranges.value_counts().sort_index())
    
else:
    print(f"ç›®æ ‡å˜é‡ {target_col} ä¸å­˜åœ¨äºæ•°æ®é›†ä¸­")

# =============================================================================
# 8. æ‰¾å‡ºä¸ Price ç›¸å…³æ€§æœ€é«˜çš„ä¸‰ä¸ªç‰¹å¾å¹¶è§£é‡Š
# =============================================================================
print("\n" + "="*60)
print("8. æ‰¾å‡ºä¸ Price ç›¸å…³æ€§æœ€é«˜çš„ä¸‰ä¸ªç‰¹å¾å¹¶è§£é‡Š")
print("="*60)

if target_col in num_columns_final:
    # è·å–ä¸ç›®æ ‡å˜é‡ç›¸å…³æ€§æœ€é«˜çš„ä¸‰ä¸ªç‰¹å¾ï¼ˆæ’é™¤ç›®æ ‡å˜é‡è‡ªèº«ï¼‰
    top_3_features = correlation_with_target.index[1:4]  # ç´¢å¼•0æ˜¯ç›®æ ‡å˜é‡è‡ªèº«
    top_3_corr_values = correlation_with_target.values[1:4]
    
    print("ä¸æˆ¿ä»·ç›¸å…³æ€§æœ€é«˜çš„ä¸‰ä¸ªç‰¹å¾æ˜¯:")
    for i, (feature, corr_val) in enumerate(zip(top_3_features, top_3_corr_values), 1):
        print(f"{i}. {feature}: {corr_val:.4f}")
    
    # ç»˜åˆ¶è¿™ä¸‰ä¸ªç‰¹å¾ä¸æˆ¿ä»·çš„å…³ç³»å›¾
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    
    for i, (feature, corr_val) in enumerate(zip(top_3_features, top_3_corr_values)):
        if feature in df_cleaned.columns:
            axes[i].scatter(df_cleaned[feature], df_cleaned[target_col], alpha=0.6, color=f'C{i}')
            axes[i].set_title(f'{feature} vs {target_col}\n(ç›¸å…³ç³»æ•°: {corr_val:.3f})')
            axes[i].set_xlabel(feature)
            axes[i].set_ylabel(target_col)
            
            # æ·»åŠ è¶‹åŠ¿çº¿
            z = np.polyfit(df_cleaned[feature], df_cleaned[target_col], 1)
            p = np.poly1d(z)
            axes[i].plot(df_cleaned[feature], p(df_cleaned[feature]), "r--", alpha=0.8)
    
    plt.tight_layout()
    plt.show()
    
    # å¯¹è¿™ä¸‰ä¸ªç‰¹å¾è¿›è¡Œè¯¦ç»†è§£é‡Š
    print("\nç‰¹å¾è§£é‡Š:")
    
    feature_explanations = {
        'OverallQual': {
            'è§£é‡Š': 'æ•´ä½“ææ–™å’Œå·¥è‰ºè´¨é‡',
            'è¯´æ˜': 'è¿™æ˜¯è¯„ä¼°æˆ¿å±‹å»ºé€ è´¨é‡çš„æœ€é‡è¦æŒ‡æ ‡ã€‚é«˜è´¨é‡æ„å‘³ç€æ›´å¥½çš„å»ºç­‘ææ–™ã€ç²¾ç¾çš„è£…ä¿®å’Œå“è¶Šçš„å·¥è‰ºï¼Œç›´æ¥å½±å“æˆ¿å±‹çš„ä»·å€¼ã€‚',
            'å½±å“': 'è´¨é‡ç­‰çº§æ¯æé«˜ä¸€çº§ï¼Œæˆ¿ä»·é€šå¸¸ä¼šæœ‰æ˜¾è‘—æå‡'
        },
        'GrLivArea': {
            'è§£é‡Š': 'åœ°é¢ä»¥ä¸Šå±…ä½é¢ç§¯',
            'è¯´æ˜': 'ä»£è¡¨æˆ¿å±‹çš„å®é™…å¯ç”¨å±…ä½ç©ºé—´å¤§å°ã€‚æ›´å¤§çš„å±…ä½é¢ç§¯æ„å‘³ç€æ›´å¤šçš„åŠŸèƒ½ç©ºé—´å’Œèˆ’é€‚åº¦ï¼Œæ˜¯æˆ¿ä»·çš„åŸºæœ¬å†³å®šå› ç´ ã€‚',
            'å½±å“': 'é¢ç§¯ä¸æˆ¿ä»·å‘ˆå¼ºæ­£ç›¸å…³ï¼Œæ˜¯è´­æˆ¿è€…æœ€å…³æ³¨çš„æŒ‡æ ‡ä¹‹ä¸€'
        },
        'GarageCars': {
            'è§£é‡Š': 'è½¦åº“å®¹é‡ï¼ˆå¯åœæ”¾è½¦è¾†æ•°ï¼‰',
            'è¯´æ˜': 'åœ¨ç°ä»£ç”Ÿæ´»ä¸­ï¼Œè½¦åº“ä¸ä»…æ˜¯åœè½¦åœºæ‰€ï¼Œä¹Ÿæ˜¯é‡è¦çš„å­˜å‚¨ç©ºé—´ã€‚èƒ½å®¹çº³æ›´å¤šè½¦è¾†çš„è½¦åº“å¤§å¤§å¢åŠ äº†æˆ¿å±‹çš„å®ç”¨æ€§ã€‚',
            'å½±å“': 'è½¦åº“å®¹é‡è¶Šå¤§ï¼Œæˆ¿å±‹ä»·å€¼è¶Šé«˜ï¼Œç‰¹åˆ«æ˜¯åœ¨æ±½è½¦æ™®åŠçš„åœ°åŒº'
        },
        'TotalBsmtSF': {
            'è§£é‡Š': 'åœ°ä¸‹å®¤æ€»é¢ç§¯',
            'è¯´æ˜': 'åœ°ä¸‹å®¤æä¾›äº†é¢å¤–çš„å¯ç”¨ç©ºé—´ï¼Œå¯ç”¨äºå­˜å‚¨ã€å¨±ä¹æˆ–æ‰©å±•å±…ä½é¢ç§¯ï¼Œå¢åŠ äº†æˆ¿å±‹çš„åŠŸèƒ½æ€§ã€‚',
            'å½±å“': 'åœ°ä¸‹å®¤é¢ç§¯ä¸æˆ¿ä»·æ­£ç›¸å…³ï¼Œä½†ç›¸å…³æ€§é€šå¸¸ä½äºåœ°ä¸Šå±…ä½é¢ç§¯'
        },
        '1stFlrSF': {
            'è§£é‡Š': 'ä¸€å±‚é¢ç§¯',
            'è¯´æ˜': 'æˆ¿å±‹ä¸»è¦ç”Ÿæ´»åŒºåŸŸçš„å¤§å°ï¼Œç›´æ¥å½±å“å±…ä½ä½“éªŒå’ŒåŠŸèƒ½æ€§ã€‚',
            'å½±å“': 'ä¸€å±‚é¢ç§¯æ˜¯å±…ä½é¢ç§¯çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œä¸æˆ¿ä»·å¼ºç›¸å…³'
        }
    }
    
    for i, feature in enumerate(top_3_features, 1):
        if feature in feature_explanations:
            explanation = feature_explanations[feature]
            print(f"\n{i}. {feature}:")
            print(f"è§£é‡Š: {explanation['è§£é‡Š']}")
            print(f"è¯´æ˜: {explanation['è¯´æ˜']}")
            print(f"å½±å“: {explanation['å½±å“']}")
        else:
            print(f"\n{i}. {feature}:")
            print("è¿™æ˜¯ä¸æˆ¿ä»·é«˜åº¦ç›¸å…³çš„æ•°å€¼ç‰¹å¾ï¼Œå…·ä½“å«ä¹‰éœ€è¦å‚è€ƒæ•°æ®æè¿°æ–‡æ¡£")
    
    print(f"\n ç»“è®º: è¿™ä¸‰ä¸ªç‰¹å¾å…±åŒè§£é‡Šäº†æˆ¿ä»·å˜å¼‚çš„å¾ˆå¤§éƒ¨åˆ†ï¼Œåœ¨æˆ¿ä»·é¢„æµ‹æ¨¡å‹ä¸­åº”è¯¥ä½œä¸ºé‡è¦ç‰¹å¾è€ƒè™‘ã€‚")
    
else:
    print(f" æ— æ³•è¿›è¡Œç›¸å…³æ€§åˆ†æï¼Œç›®æ ‡å˜é‡ {target_col} å¯èƒ½ä¸æ˜¯æ•°å€¼ç±»å‹")

# =============================================================================
# 9. æœ€ç»ˆæ•°æ®æ€»ç»“
# =============================================================================
print("\n" + "="*60)
print("9. æ•°æ®é¢„å¤„ç†æ€»ç»“")
print("="*60)

print(" é¢„å¤„ç†æµç¨‹æ€»ç»“:")
print(f"â€¢ åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
print(f"â€¢ æ¸…ç†åæ•°æ®å½¢çŠ¶: {df_cleaned.shape}")
print(f"â€¢ å¤„ç†ç¼ºå¤±å€¼: {len(missing_data) if len(missing_data) > 0 else 0} ä¸ªç‰¹å¾æœ‰ç¼ºå¤±å€¼")
print(f"â€¢ åˆ é™¤å¼‚å¸¸å€¼: {original_shape[0] - df_cleaned.shape[0]} è¡Œ")

if target_col in df_cleaned.columns:
    print(f"â€¢ ç›®æ ‡å˜é‡: {target_col}")
    print(f"â€¢ ä»·æ ¼èŒƒå›´: ${df_cleaned[target_col].min():,.0f} - ${df_cleaned[target_col].max():,.0f}")
    print(f"â€¢ å¹³å‡ä»·æ ¼: ${df_cleaned[target_col].mean():,.0f}")

print("\n æ•°æ®é¢„å¤„ç†å®Œæˆï¼æ•°æ®å·²å‡†å¤‡å¥½ç”¨äºè¿›ä¸€æ­¥åˆ†ææˆ–å»ºæ¨¡ã€‚")

# æ˜¾ç¤ºæœ€ç»ˆæ•°æ®çš„å‰å‡ è¡Œ
print("\n é¢„å¤„ç†åçš„æ•°æ®å‰3è¡Œ:")
display(df_cleaned.head(3))

# ä¿å­˜æ¸…ç†åçš„æ•°æ®ï¼ˆå¯é€‰ï¼‰
try:
    df_cleaned.to_csv('house_data_cleaned.csv', index=False)
    print(" æ¸…ç†åçš„æ•°æ®å·²ä¿å­˜ä¸º 'house_data_cleaned.csv'")
except Exception as e:
    print(f" ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")

print("\n å®éªŒäºŒï¼šæ•°æ®é¢„å¤„ç†å®Œæˆï¼")