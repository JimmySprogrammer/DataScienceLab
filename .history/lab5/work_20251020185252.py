import pandas as pd
import os

def read_csv_safely(filepath):
    encodings = ['utf-8', 'utf-8-sig', 'latin1', 'iso-8859-1', 'cp1252']
    for enc in encodings:
        for skip in range(0, 10):  # å°è¯•è·³è¿‡å‰0~9è¡Œ
            try:
                df = pd.read_csv(filepath, encoding=enc, skiprows=skip)
                if len(df.columns) > 3 and not df.columns[0].startswith("Indicators"):
                    print(f"âœ… æˆåŠŸè¯»å–: {os.path.basename(filepath)}ï¼Œç¼–ç ={enc}ï¼Œè·³è¿‡å‰{skip}è¡Œï¼Œåˆ—={list(df.columns)[:5]}")
                    return df
            except Exception:
                continue
    print(f"âŒ æ— æ³•è§£æ {os.path.basename(filepath)} çš„æ•°æ®ç»“æ„")
    return None

def load_all_data(data_dir):
    data = []
    print(f"\nğŸ“‚ ä» {data_dir} åŠ è½½æ•°æ®...\n")
    for fname in os.listdir(data_dir):
        if fname.endswith(".csv"):
            fpath = os.path.join(data_dir, fname)
            df = read_csv_safely(fpath)
            if df is not None and len(df.columns) > 1:
                df['Discipline'] = fname.replace('.csv', '')
                data.append(df)
    return data

def analyze_global_clusters(dataframes):
    if not dataframes:
        raise ValueError("âŒ æ²¡æœ‰å¯ç”¨æ•°æ®ï¼Œè¯·æ£€æŸ¥CSVç»“æ„")
    merged = pd.concat(dataframes, ignore_index=True)
    print(f"âœ… æˆåŠŸåˆå¹¶ {len(dataframes)} ä¸ªå­¦ç§‘ï¼Œæ€»è¡Œæ•°: {len(merged)}")
    return merged

def main():
    data_dir = r"D:\DataScienceLab\lab5\data"
    data = load_all_data(data_dir)

    print("\n=== ç¬¬8é¢˜ï¼šå…¨çƒé«˜æ ¡åˆ†ç±»åˆ†æ ===")
    merged = analyze_global_clusters(data)

    output_path = os.path.join(data_dir, "merged_all.csv")
    merged.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"âœ… å·²ä¿å­˜åˆå¹¶åçš„æ–‡ä»¶: {output_path}")

if __name__ == "__main__":
    main()
