# -*- coding: utf-8 -*-
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

def main():
    path = r"D:\DataScienceLab\lab5\data\merged_all.csv"
    print(f"ğŸ“Š æ­£åœ¨è¯»å–åˆå¹¶æ•°æ®ï¼š{path}\n")

    # ---------- è¯»å–ä¸æ¸…æ´— ----------
    try:
        df = pd.read_csv(path, encoding="utf-8")
    except UnicodeDecodeError:
        df = pd.read_csv(path, encoding="latin1")

    # ä¿®æ­£åˆ—åä¹±ç 
    df.columns = [c.replace("Ã¯Â»Â¿", "").strip() for c in df.columns]
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œæ€»è¡Œæ•°: {len(df)}")
    print(f"ğŸ“‘ åˆ—: {list(df.columns)}")

    # ---------- ç¬¬8é¢˜ï¼šå…¨çƒé«˜æ ¡èšç±»åˆ†æ ----------
    print("\n=== ç¬¬8é¢˜ï¼šå…¨çƒé«˜æ ¡åˆ†ç±»åˆ†æ ===")
    data = df.dropna(subset=["Cites", "Web of Science Documents", "Cites/Paper", "Top Papers"])
    features = ["Web of Science Documents", "Cites", "Cites/Paper", "Top Papers"]
    X = data[features]
    X_scaled = StandardScaler().fit_transform(X)

    kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)
    data["Cluster"] = kmeans.fit_predict(X_scaled)
    print("âœ… æˆåŠŸå®Œæˆèšç±»åˆ†æï¼ˆå…±åˆ†5ç±»ï¼‰")
    print(data["Cluster"].value_counts().to_frame("Institutions"))

    # å¯è§†åŒ–èšç±»ç»“æœ
    plt.figure(figsize=(8, 6))
    plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=data["Cluster"], cmap="rainbow", s=10)
    plt.title("Global University Clusters", fontsize=14)
    plt.xlabel("Standardized Web of Science Documents")
    plt.ylabel("Standardized Cites")
    plt.savefig("cluster_plot.png", dpi=300, bbox_inches="tight")
    print("ğŸ“ˆ å·²ç”Ÿæˆèšç±»åˆ†å¸ƒå›¾ cluster_plot.png")

    # æŸ¥æ‰¾ä¸åä¸œå¸ˆèŒƒå¤§å­¦ç›¸ä¼¼é«˜æ ¡
    target_name = "EAST CHINA NORMAL UNIVERSITY"
    if target_name in data["Institutions"].values:
        target_cluster = data.loc[data["Institutions"] == target_name, "Cluster"].values[0]
        similar = data[data["Cluster"] == target_cluster][["Institutions", "Cites", "Web of Science Documents"]].head(10)
        print(f"\nä¸ã€{target_name}ã€‘ç›¸ä¼¼çš„é«˜æ ¡åŒ…æ‹¬ï¼š")
        print(similar)
    else:
        print(f"\næœªæ‰¾åˆ°é«˜æ ¡ï¼š{target_name}")

    # ---------- ç¬¬9é¢˜ï¼šåä¸œå¸ˆèŒƒå¤§å­¦å­¦ç§‘ç”»åƒ ----------
    print("\n=== ç¬¬9é¢˜ï¼šåä¸œå¸ˆèŒƒå¤§å­¦å­¦ç§‘ç”»åƒ ===")
    ecnu = df[df["Institutions"] == "EAST CHINA NORMAL UNIVERSITY"]
    if ecnu.empty:
        print("âš ï¸ æœªæ‰¾åˆ°åä¸œå¸ˆèŒƒå¤§å­¦ç›¸å…³æ•°æ®ï¼Œè·³è¿‡æ­¤éƒ¨åˆ†ã€‚")
    else:
        discipline_stats = ecnu.groupby("Discipline")[["Web of Science Documents", "Cites", "Top Papers"]].sum()
        discipline_stats.plot(kind="barh", figsize=(8, 6), color=["#4C72B0", "#55A868", "#C44E52"])
        plt.title("Discipline Profile of EAST CHINA NORMAL UNIVERSITY", fontsize=14)
        plt.xlabel("Value")
        plt.tight_layout()
        plt.savefig("ecnu_profile.png", dpi=300)
        print("ğŸ“Š å·²ç”Ÿæˆåä¸œå¸ˆå¤§å­¦ç§‘ç”»åƒ ecnu_profile.png")

    # ---------- ç¬¬10é¢˜ï¼šæ’åé¢„æµ‹æ¨¡å‹ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ ----------
    print("\n=== ç¬¬10é¢˜ï¼šæ’åé¢„æµ‹æ¨¡å‹ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ ===")
    model_df = df.copy()
    model_df = model_df.dropna(subset=["Cites", "Web of Science Documents", "Cites/Paper", "Top Papers"])

    features = ["Web of Science Documents", "Cites/Paper", "Top Papers"]
    target = "Cites"
    train_list, test_list = [], []

    # æŒ‰å­¦ç§‘åˆ’åˆ†è®­ç»ƒé›†ä¸æµ‹è¯•é›†
    for disc, group in model_df.groupby("Discipline"):
        group = group.sort_values(by="Cites", ascending=False)
        n = len(group)
        if n < 10:
            continue
        train_end = int(n * 0.6)
        test_start = int(n * 0.8)
        train_list.append(group.iloc[:train_end])
        test_list.append(group.iloc[test_start:])

    train_df = pd.concat(train_list)
    test_df = pd.concat(test_list)

    X_train, y_train = train_df[features], train_df[target]
    X_test, y_test = test_df[features], test_df[target]

    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)

    print(f"ğŸ“ˆ ä½¿ç”¨å„å­¦ç§‘å‰60%è®­ç»ƒã€å20%æµ‹è¯•")
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_df)}, æµ‹è¯•æ ·æœ¬æ•°: {len(test_df)}")
    print(f"æ¨¡å‹é¢„æµ‹ RÂ² å¾—åˆ†: {r2:.4f}")

    result_df = test_df[["Institutions", "Discipline", "Cites"]].copy()
    result_df["Predicted Cites"] = y_pred
    print("\nç¤ºä¾‹é¢„æµ‹ç»“æœå‰10è¡Œï¼š")
    print(result_df.head(10))

if __name__ == "__main__":
    main()
