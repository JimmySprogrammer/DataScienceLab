# eight.py
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

path = r"D:\DataScienceLab\lab5\data\merged_all.csv"

print(f"ğŸ“Š æ­£åœ¨è¯»å–åˆå¹¶æ•°æ®ï¼š{path}")
df = pd.read_csv(path, encoding="latin1")

# å»é™¤BOMå¤´å¹¶è§„èŒƒåˆ—å
df.columns = [c.strip().replace("Ã¯Â»Â¿", "") for c in df.columns]

print(f"\nâœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œæ€»è¡Œæ•°: {len(df)}")
print(f"ğŸ“‘ åˆ—: {df.columns.tolist()[:8]}")

# å»é™¤ç©ºå€¼
df = df.dropna(subset=["Institutions", "Countries/Regions", "Cites", "Web of Science Documents"])

# ========== ç¬¬8é¢˜ï¼šå…¨çƒé«˜æ ¡åˆ†ç±»åˆ†æ ==========
print("\n=== ç¬¬8é¢˜ï¼šå…¨çƒé«˜æ ¡åˆ†ç±»åˆ†æ ===")

# èšåˆå„é«˜æ ¡çš„è®ºæ–‡ä¸å¼•ç”¨è¡¨ç°
inst_summary = df.groupby("Institutions").agg({
    "Web of Science Documents": "sum",
    "Cites": "sum",
    "Cites/Paper": "mean",
    "Top Papers": "sum"
}).reset_index()

# æ ‡å‡†åŒ–å¤„ç†
features = inst_summary[["Web of Science Documents", "Cites", "Cites/Paper", "Top Papers"]].fillna(0)
X = StandardScaler().fit_transform(features)

# KMeansèšç±»
kmeans = KMeans(n_clusters=5, random_state=42)
inst_summary["Cluster"] = kmeans.fit_predict(X)

print("âœ… æˆåŠŸå®Œæˆèšç±»åˆ†æï¼ˆå…±åˆ†5ç±»ï¼‰")
print(inst_summary.groupby("Cluster").agg({"Institutions": "count"}))

# ç»˜åˆ¶èšç±»æ•£ç‚¹å›¾
plt.figure(figsize=(8,6))
plt.scatter(inst_summary["Cites"], inst_summary["Web of Science Documents"],
            c=inst_summary["Cluster"], cmap="tab10", s=20, alpha=0.7)
plt.xlabel("Cites")
plt.ylabel("Web of Science Documents")
plt.title("Global University Clustering")
plt.savefig(r"D:\DataScienceLab\lab5\cluster_plot.png", dpi=300)
print("ğŸ“ˆ å·²ç”Ÿæˆèšç±»åˆ†å¸ƒå›¾ cluster_plot.png")

# æ‰¾å‡ºä¸åä¸œå¸ˆèŒƒå¤§å­¦ç›¸ä¼¼çš„é«˜æ ¡
target = "EAST CHINA NORMAL UNIVERSITY"
if target in inst_summary["Institutions"].values:
    cluster_id = inst_summary.loc[inst_summary["Institutions"] == target, "Cluster"].iloc[0]
    similar = inst_summary[inst_summary["Cluster"] == cluster_id].head(10)
    print(f"\nä¸ã€{target}ã€‘ç›¸ä¼¼çš„é«˜æ ¡åŒ…æ‹¬ï¼š")
    print(similar[["Institutions", "Cites", "Web of Science Documents"]])
else:
    print(f"âš ï¸ æ•°æ®ä¸­æœªæ‰¾åˆ° {target}")

# ========== ç¬¬9é¢˜ï¼šå­¦ç§‘ç”»åƒ ==========
print("\n=== ç¬¬9é¢˜ï¼šåä¸œå¸ˆèŒƒå¤§å­¦å­¦ç§‘ç”»åƒ ===")
ecnu = df[df["Institutions"].str.contains("EAST CHINA NORMAL UNIVERSITY", case=False, na=False)]

if len(ecnu) > 0:
    plt.figure(figsize=(8,6))
    plt.barh(ecnu["Discipline"], ecnu["Cites"], color="black")
    plt.xlabel("Citations")
    plt.ylabel("Discipline")
    plt.title("Discipline Profile of East China Normal University")
    plt.tight_layout()
    plt.savefig(r"D:\DataScienceLab\lab5\ecnu_profile.png", dpi=300)
    print("ğŸ“Š å·²ç”Ÿæˆåä¸œå¸ˆå¤§å­¦ç§‘ç”»åƒ ecnu_profile.png")
else:
    print("âš ï¸ æ•°æ®ä¸­æœªæ‰¾åˆ°åä¸œå¸ˆèŒƒå¤§å­¦çš„å­¦ç§‘è®°å½•")

# ========== ç¬¬10é¢˜ï¼šé¢„æµ‹æ¨¡å‹ ==========
print("\n=== ç¬¬10é¢˜ï¼šæ’åé¢„æµ‹æ¨¡å‹ ===")
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

df["Rank"] = df.groupby("Discipline")["Cites"].rank(ascending=False, method="dense")

X = df[["Cites", "Web of Science Documents", "Cites/Paper", "Top Papers"]].fillna(0)
y = df["Rank"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print(f"æ¨¡å‹é¢„æµ‹RÂ²å¾—åˆ†: {r2_score(y_test, y_pred):.3f}")
