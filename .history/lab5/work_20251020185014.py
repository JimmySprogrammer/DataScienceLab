import pandas as pd
import os

def read_csv_safely(filepath):
    encodings = ['utf-8', 'utf-8-sig', 'latin1', 'iso-8859-1', 'cp1252']
    for enc in encodings:
        try:
            df = pd.read_csv(filepath, encoding=enc)
            print(f"âœ… æˆåŠŸè¯»å–: {os.path.basename(filepath)}ï¼Œç¼–ç ={enc}ï¼Œåˆ—={list(df.columns)[:5]}")
            return df
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å– {os.path.basename(filepath)}ï¼Œå°è¯•ç¼–ç  {enc}ï¼Œé”™è¯¯ï¼š{str(e)[:100]}")
    return None

def load_all_data(data_dir):
    data = []
    print(f"\nğŸ“‚ ä» {data_dir} åŠ è½½æ•°æ®...\n")
    for fname in os.listdir(data_dir):
        if fname.endswith(".csv"):
            fpath = os.path.join(data_dir, fname)
            df = read_csv_safely(fpath)
            if df is not None and len(df.columns) > 1:
                df['SourceFile'] = fname.replace('.csv', '')
                data.append(df)
    return data

def analyze_global_clusters(dataframes):
    if not dataframes:
        raise ValueError("âŒ æ²¡æœ‰å¯ç”¨æ•°æ®ï¼Œè¯·æ£€æŸ¥CSVç»“æ„")
    merged = pd.concat(dataframes, ignore_index=True)
    print(f"âœ… æˆåŠŸåˆå¹¶ {len(dataframes)} ä¸ªå­¦ç§‘ï¼Œæ€»è¡Œæ•°: {len(merged)}")
    return merged

def main():
    data_dir = r"D:\DataScienceLab\lab5\data"
    data = load_all_data(data_dir)

    print("\n=== ç¬¬8é¢˜ï¼šå…¨çƒé«˜æ ¡åˆ†ç±»åˆ†æ ===")
    merged = analyze_global_clusters(data)

    merged.to_csv(os.path.join(data_dir, "merged_all.csv"), index=False, encoding='utf-8-sig')
    print("âœ… å·²ä¿å­˜åˆå¹¶åçš„æ–‡ä»¶: merged_all.csv")

if __name__ == "__main__":
    main()
